{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMkjctPtlDo51JHluO3KnP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K44Ll/Machine-Learning/blob/master/Fun%C3%A7oes_de_perda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções de perda"
      ],
      "metadata": {
        "id": "NyrlZisyZ5VY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i8Kg_kajZGyi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Ir517EZcaY",
        "outputId": "b4c2ab40-3ff9-4959-9032-62a5f742255c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trabalharemos com o [dataset de classificação de vinhos](https://scikit-learn.org/0.21/modules/generated/sklearn.datasets.load_wine.html)"
      ],
      "metadata": {
        "id": "FezcVvh_aAPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "wine = datasets.load_wine()\n",
        "data = wine.data\n",
        "target = wine.target\n",
        "\n",
        "print(data.shape)\n",
        "print(target.shape)\n",
        "print(\"---\")\n",
        "print(wine.feature_names, wine.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMAIEa2aaMB8",
        "outputId": "dcbea7eb-d3b2-4af3-afb8-adaea5fddd57"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n",
            "(178,)\n",
            "---\n",
            "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] ['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instanciar um mlp (camadas)"
      ],
      "metadata": {
        "id": "SbcSG49zbNnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class wineclassifier(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(wineclassifier, self).__init__()\n",
        "\n",
        "    self.hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, out_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    feature = self.relu(self.hidden(x))\n",
        "    output = self.softmax(self.out(feature))\n",
        "\n",
        "input_size = data.shape[1]\n",
        "hidden_size = 32\n",
        "out_size = len(wine.target_names)\n",
        "net = wineclassifier(input_size, hidden_size, out_size).to(device)"
      ],
      "metadata": {
        "id": "czh-jNb-bQDx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação"
      ],
      "metadata": {
        "id": "2e7lwMW8czzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterio = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "glzAbGsgc1WQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tns = torch.from_numpy(data).float().to(device)\n",
        "y_tns = torch.from_numpy(target).to(device)\n",
        "\n",
        "print(f'X: {X_tns.dtype}')\n",
        "print(f'y: {y_tns.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtEyYUPTdAcF",
        "outputId": "7a7f619d-1665-4f92-c205-92cffd0e6860"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: torch.float32\n",
            "y: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = net(X_tns)"
      ],
      "metadata": {
        "id": "AJcpCHaAdgBd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred.shape, y_tns.shape)\n",
        "\n",
        "print(pred[0].data, y_tns[0].data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FygKAKsbeuX0",
        "outputId": "73f41546-19c9-46de-dae1-0ef2ff1d3488"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([178, 3]) torch.Size([178])\n",
            "tensor([0., 1., 0.], device='cuda:0') tensor(0, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterio(pred, y_tns)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_vpsquWfUHc",
        "outputId": "ecb3a4b6-ddac-4307-8412-ce74d0fc8d84"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regressão"
      ],
      "metadata": {
        "id": "isTKuZ2Afxgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos usar o dataset sobre diabates"
      ],
      "metadata": {
        "id": "oThCjlIPgwr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "diabetes = datasets.load_diabetes()\n",
        "data = diabetes.data\n",
        "target = diabetes.target\n",
        "\n",
        "print(data.shape, target.shape)\n",
        "print('---')\n",
        "print(data[14])\n",
        "print(target[14])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY98iNztg2_8",
        "outputId": "53178147-ea45-4a4a-e46f-f3c79aa5a4fb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10) (442,)\n",
            "---\n",
            "[ 4.53409833e-02 -4.46416365e-02 -2.56065715e-02 -1.25561242e-02\n",
            "  1.76943802e-02 -6.12835791e-05  8.17748397e-02 -3.94933829e-02\n",
            " -3.19876395e-02 -7.56356220e-02]\n",
            "118.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Honq4dZ3h3hg",
        "outputId": "88108c43-d2db-4045-d22c-566122be5b09"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "-SzsPdA6hbz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class diabetesclass(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(diabetesclass, self).__init__()\n",
        "\n",
        "    self.hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, out_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    feature = self.relu(self.hidden(x))\n",
        "    output = self.softmax(self.out(feature))\n",
        "    return output # Added return statement to return the output\n",
        "\n",
        "input_size = data.shape[1]\n",
        "hidden_size = 32\n",
        "out_size = 1 # progressão da diabetes\n",
        "net = diabetesclass(input_size, hidden_size, out_size).to(device)"
      ],
      "metadata": {
        "id": "v5CN8Z_xhbHD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "func de perda"
      ],
      "metadata": {
        "id": "y6Rcv48_iEXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss().to(device) # cast na GPU\n",
        "\n",
        "x_tensor = torch.from_numpy(data).float().to(device)\n",
        "y_tensor = torch.from_numpy(target).float().to(device)\n",
        "\n",
        "print(x_tensor.shape)\n",
        "print(y_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbecISJNiFQR",
        "outputId": "c3131b96-13ea-464d-e0b0-b9ebaa8e0d35"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([442, 10])\n",
            "torch.Size([442])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predi = net(x_tensor)\n",
        "\n",
        "loss = criterion(predi.squeeze(), y_tensor)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yO_7CUwikio",
        "outputId": "cf56da9b-066a-481b-8b07-7285599a1229"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(28771.2168, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}